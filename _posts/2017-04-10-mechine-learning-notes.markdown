---
layout: post
title:  "machine learning reading notes"
date:   2017-04-10 14:16:07 +0800
categories: reading notes
---
## 神经网络
* 感知机：由两层神经元组成
* 由于神经网络的层数比较少，因此学习能力比较有限
* 如果线性的模式是可分的， 那么一定会收敛，否则会发生震荡
* 多层前馈神经网络
    * 每一层与下一层连接
    * 同层不能连接
    * 不能跨层连接

### BP神经网络
* 比较容易遇到过拟合的状况
* 解决方法是早停或者是正则化
* 如何跳出局部的最优解
    * 模拟退火
    * 采用多组不同参数初始化的神经网络
    * 随机梯度下降
* 其他的神经网络
    * 径向基函数 神经网络
    * ART网络  竞争型学习
    
### 深度学习
* 逐层训练 + 整体微调
* 权共享 ： 让一组神经元使用相同的连接权
* 没有看懂 手写识别的过程

## 支持向量
* 距离超平面最近的训练样本
* 支持向量机 最大化间隔
    * 间隔：

![支持向量机的间隔](http://upload-images.jianshu.io/upload_images/4860101-6cb97c04a30bafec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

* 核函数： 把训练集投射到更高维度的空间中，简化了内积运算的求解
    * 核函数还可以通过线性组合，直积以及函数嵌套的方式进行重组

